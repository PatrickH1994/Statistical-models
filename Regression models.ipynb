{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18b5b3cb",
   "metadata": {},
   "source": [
    "In this notebook I use numpy to code from scratch different regression models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "e95891f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "LEARNING_RATE = 0.0005\n",
    "\n",
    "class Linear_regression:\n",
    "    def __init__(self):\n",
    "        self.intercept = 0\n",
    "        self.b1 = 0\n",
    "        \n",
    "    def predict(self, value):\n",
    "        return self.intercept + value * self.b1\n",
    "    \n",
    "    def predict_array(self, x):\n",
    "        return np.array([self.predict(xi) for xi in x])\n",
    "    \n",
    "    def OLS_estimator(self, y, x):\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        This function uses the OLS estimator to estimate the coefficients.\n",
    "        \n",
    "        FORMULA:\n",
    "        \n",
    "        m= sum((xi-mean(x))(yi-mean(y))) / sum((xi-mean(x))**2)\n",
    "        b= mean(y) - m*mean(x)\n",
    "        \n",
    "        \"\"\"\n",
    "        mean_x = np.mean(x)\n",
    "        mean_y = np.mean(y)\n",
    "        \n",
    "        nominator = 0\n",
    "        denominator = 0\n",
    "        \n",
    "        for xi,yi in zip(x,y):\n",
    "            nominator += (xi-mean_x)*(yi-mean_y)\n",
    "            denominator += (xi-mean_x)**2\n",
    "            \n",
    "        self.b1 = nominator / denominator\n",
    "        self.intercept = mean_y - self.b1 * mean_x\n",
    "        \n",
    "        \n",
    "        print(f'Intercept = {round(self.intercept, 3)}\\nBeta = {round(self.b1,3)} ')\n",
    "    \n",
    "    def gradient_descent(self, y, x, learning_rate = LEARNING_RATE, epochs = 30000):\n",
    "    \n",
    "        \"\"\"\n",
    "\n",
    "        This function uses gradient descent to estimate the coefficients.\n",
    "\n",
    "        FORMULA:\n",
    "        \n",
    "        Intercept = Intercept -alpha/m * sum((pred(y)-real(y)))\n",
    "        b1 = b1 -alpha/m * sum((pred(y)-real(y))*x)\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        m = len(y)\n",
    "    \n",
    "        for _ in range(epochs):\n",
    "            \n",
    "            y_pred = self.predict_array(x)\n",
    "            \n",
    "            self.intercept = self.intercept - learning_rate * (1/m) * (np.sum(y_pred-y))\n",
    "            self.b1 = self.b1 - learning_rate * (1/m) * (np.sum((y_pred-y)*x))\n",
    "\n",
    "        print(f'Gradient descent results\\nIntercept: {self.intercept}\\nBeta: {self.b1}')\n",
    "    \n",
    "    def null_values(self):\n",
    "        self.b1 = 0\n",
    "        self.intercept = 0\n",
    "#         print(f'Intercept: {self.intercept}\\nBeta: {self.b1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "ef290e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without noise we expect the intercept to be 0 and beta to be 1.\n",
      "Intercept = 0.0\n",
      "Beta = 1.0 \n",
      "\n",
      "With noise we expect the two values to deviate a little from the correct values\n",
      "Intercept = -0.5\n",
      "Beta = 1.0 \n",
      "\n",
      "With a random function we expect the values to be very different\n",
      "Intercept = 31.165\n",
      "Beta = 0.805 \n"
     ]
    }
   ],
   "source": [
    "#Initiate model\n",
    "ols = Linear_regression()\n",
    "\n",
    "#Data with noise\n",
    "print(\"Without noise we expect the intercept to be 0 and beta to be 1.\")\n",
    "y = np.array([i for i in range(1, 100, 1)])\n",
    "x = np.array([i for i in y])\n",
    "ols.OLS_estimator(y, x)\n",
    "\n",
    "#Data with little noise\n",
    "print(\"\\nWith noise we expect the two values to deviate a little from the correct values\")\n",
    "x = np.array([i+np.random.random() for i in y])\n",
    "ols.OLS_estimator(y, x)\n",
    "\n",
    "#Data with a random function\n",
    "print(\"\\nWith a random function we expect the values to be very different\")\n",
    "x = np.array([i*np.random.random() for i in y])\n",
    "ols.OLS_estimator(y, x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "43084b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without noise we expect the intercept to be 0 and beta to be 1.\n",
      "Intercept = 0.0\n",
      "Beta = 1.0 \n",
      "\n",
      "\n",
      "Gradient descent results\n",
      "Intercept: 0.00037533149963272437\n",
      "Beta: 0.999994341316178\n",
      "\n",
      "####################\n",
      "####################\n",
      "####################\n",
      "\n",
      "With noise we expect the two values to deviate a little from the correct values\n",
      "Intercept = -0.527\n",
      "Beta = 1.001 \n",
      "\n",
      "\n",
      "Gradient descent results\n",
      "Intercept: -0.5130418798440008\n",
      "Beta: 1.0007116855736493\n",
      "\n",
      "####################\n",
      "####################\n",
      "####################\n",
      "\n",
      "With a random function we expect the values to be very different\n",
      "Intercept = 32.866\n",
      "Beta = 0.799 \n",
      "\n",
      "\n",
      "Gradient descent results\n",
      "Intercept: 32.827537525222525\n",
      "Beta: 0.799663226433088\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Testing the difference between OLS estimation and gradient descent.\n",
    "\"\"\"\n",
    "\n",
    "#Initiate model\n",
    "ols = Linear_regression()\n",
    "\n",
    "#Data with noise\n",
    "print(\"Without noise we expect the intercept to be 0 and beta to be 1.\")\n",
    "y = np.array([i for i in range(1, 100, 1)])\n",
    "x = np.array([i for i in y])\n",
    "ols.OLS_estimator(y, x)\n",
    "ols.null_values()\n",
    "print('\\n')\n",
    "ols.gradient_descent(y,x)\n",
    "\n",
    "print(\"\\n####################\\n####################\\n####################\")\n",
    "#Data with little noise\n",
    "print(\"\\nWith noise we expect the two values to deviate a little from the correct values\")\n",
    "x = np.array([i+np.random.random() for i in y])\n",
    "ols.OLS_estimator(y, x)\n",
    "ols.null_values()\n",
    "print('\\n')\n",
    "ols.gradient_descent(y,x)\n",
    "\n",
    "#Data with a random function\n",
    "print(\"\\n####################\\n####################\\n####################\")\n",
    "print(\"\\nWith a random function we expect the values to be very different\")\n",
    "x = np.array([i*np.random.random() for i in y])\n",
    "ols.OLS_estimator(y, x)\n",
    "ols.null_values()\n",
    "print('\\n')\n",
    "ols.gradient_descent(y,x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b440389c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
